{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+--------+---------+\n",
      "|COUNTY_ID|COUNTY| FLD01| FLD02|   FLD03|INFO_TIME|\n",
      "+---------+------+------+------+--------+---------+\n",
      "|     縣市代碼|  縣市名稱|  申請人數|聘僱許可人數|有效聘僱許可人數|     資料時間|\n",
      "|    65000|   新北市| 43347| 41424|    3157|     106Y|\n",
      "|    63000|   臺北市|223271|214518|   13681|     106Y|\n",
      "|    68000|   桃園市| 32575| 31353|    2613|     106Y|\n",
      "|    66000|   臺中市| 44633| 42743|    3069|     106Y|\n",
      "|    67000|   臺南市| 25247| 24410|    1003|     106Y|\n",
      "|    64000|   高雄市| 42753| 40914|    2401|     106Y|\n",
      "|    10002|   宜蘭縣|  8363|  8143|     101|     106Y|\n",
      "|    10004|   新竹縣| 13428| 12946|    1047|     106Y|\n",
      "|    10005|   苗栗縣|  6684|  6461|     375|     106Y|\n",
      "|    10007|   彰化縣|  5931|  5712|     304|     106Y|\n",
      "|    10008|   南投縣|  2947|  2712|     149|     106Y|\n",
      "|    10009|   雲林縣|  9052|  8744|     491|     106Y|\n",
      "|    10010|   嘉義縣|  3572|  3451|      93|     106Y|\n",
      "|    10013|   屏東縣|  6455|  6253|     228|     106Y|\n",
      "|    10014|   臺東縣|  2362|  2244|      47|     106Y|\n",
      "|    10015|   花蓮縣|  3470|  3346|     161|     106Y|\n",
      "|    10016|   澎湖縣|   269|   253|      15|     106Y|\n",
      "|    10017|   基隆市|  1842|  1727|      90|     106Y|\n",
      "|    10018|   新竹市| 27991| 27425|    1819|     106Y|\n",
      "+---------+------+------+------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder.enableHiveSupport().master('yarn').getOrCreate()\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty(\"hive.metastore.uris\", \"thrift://master.bdp.com:10000\")\n",
    "#df=spark.read.csv(\"input/test.csv\")\n",
    "df=spark.read.option(\"header\", \"true\").csv(\"testchh.csv\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用udf加密,jar file = dfEncrypt_3.jar, myLogging_1.jar(for java logging)\n",
    "def udfEncCols(encList, df, key_,sqlContext_):\n",
    "    sqlContext = sqlContext_\n",
    "    #_logger.debug(\"in udfEncCols\")\n",
    "    #_logger.debug(encList)\n",
    "    #####citc, 20181015 add for spark 2.0############\n",
    "    df.write.format(\"orc\").mode(\"overwrite\").saveAsTable(\"DF_Table__\")\n",
    "    sqlContext.sql(\"create temporary function udfEnc_ as 'citc.udfEncrypt.udfEnc'\")\n",
    "    #######################################################3\n",
    "    #key_ = \"Bar12345Bar12345Bar12345Bar12345\"\n",
    "    cols = df.columns\n",
    "    tmpStr=\"select \"\n",
    "    \n",
    "    \n",
    "    for colNam_ in cols:\n",
    "        if colNam_ in cols[-1:]:\n",
    "            if colNam_ not in encList:\n",
    "                tmpStr=tmpStr+ colNam_+\" from DF_Table__\"\n",
    "            else:\n",
    "                tmpStr=tmpStr+ \"udfEnc_(\"+colNam_+\", \\\"\"+key_+\"\\\") as \"+colNam_+\" from DF_Table__\"\n",
    "            break;\n",
    "        if colNam_ not in encList:\n",
    "            tmpStr=tmpStr+ colNam_+\",\"\n",
    "        else:\n",
    "            tmpStr=tmpStr+ \"udfEnc_(\"+colNam_+\", \\\"\"+key_+\"\\\") as \"+colNam_+\",\"\n",
    "    print (tmpStr)\n",
    "    #_logger.debug(tmpStr)\n",
    "    \n",
    "    \n",
    "    df2=sqlContext.sql(tmpStr)\n",
    "    #df2.show()\n",
    "\n",
    "    return df2\n",
    "\n",
    "\n",
    "def udfDecCols(encList, df, key_,sqlContext_):\n",
    "    sqlContext = sqlContext_\n",
    "    #_logger.debug(\"in udfEncCols\")\n",
    "    #_logger.debug(encList)\n",
    "    #####citc, 20181015 add for spark 2.0############\n",
    "    df.write.format(\"orc\").mode(\"overwrite\").saveAsTable(\"DF_Table__\")\n",
    "    sqlContext.sql(\"create temporary function udfDec_ as 'citc.udfEncrypt.udfDec'\")\n",
    "    #######################################################3\n",
    "    #key_ = \"Bar12345Bar12345Bar12345Bar12345\"\n",
    "    cols = df.columns\n",
    "    tmpStr=\"select \"\n",
    "    \n",
    "    \n",
    "    for colNam_ in cols:\n",
    "        if colNam_ in cols[-1:]:\n",
    "            if colNam_ not in encList:\n",
    "                tmpStr=tmpStr+ colNam_+\" from DF_Table__\"\n",
    "            else:\n",
    "                tmpStr=tmpStr+ \"udfDec_(\"+colNam_+\", \\\"\"+key_+\"\\\") as \"+colNam_+\" from DF_Table__\"\n",
    "            break;\n",
    "        if colNam_ not in encList:\n",
    "            tmpStr=tmpStr+ colNam_+\",\"\n",
    "        else:\n",
    "            tmpStr=tmpStr+ \"udfDec_(\"+colNam_+\", \\\"\"+key_+\"\\\") as \"+colNam_+\",\"\n",
    "    print (tmpStr)\n",
    "    #_logger.debug(tmpStr)\n",
    "    \n",
    "    \n",
    "    df2=sqlContext.sql(tmpStr)\n",
    "    #df2.show()\n",
    "\n",
    "    return df2\n",
    "    \n",
    "\n",
    "\n",
    "#df.write.format(\"orc\").mode(\"overwrite\").saveAsTable(\"testTBL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'funniest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-37b29415bbd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfunniest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHiveLibs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunniest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_getLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from funniest.logging_tester import HiveLibs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#import funniest.HiveLibs import Join\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'funniest'"
     ]
    }
   ],
   "source": [
    "from funniest import HiveLibs\n",
    "from funniest.logging_tester import _getLogger\n",
    "#from funniest.logging_tester import HiveLibs\n",
    "#import funniest.HiveLibs import Join\n",
    "import logging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
