@using System.Globalization
@using Resources
@inject ILocalizer localizer
<section class="about_banner">
    <div class="container-fluid">
        <div class="row">
            <div class="col-sm-12 banner">
                <h1 class="title text-center"><strong>具備隱私保護的去識別化技術</strong></h1>
            </div>
        </div>
    </div>
</section>
<br><br>
<section class="section_about">
    <div class="container">
        <div class="row">
			<div class="col-sm-12">
				<h4>去識別化技術說明</h4>
				<p>
					去識別化的主要目的為提供資料擁有者將其敏感資料進行合規的資料隱私保護，使其可釋出利用，防止接收者或是其相關成員識別出資料集的個體。而去識別化技術主要針對結構化資料集將含個資的部分資料特徵去除，讓惡意攻擊者或是資料分析者無法明確識別出資料集中的個體。<br><br>目前常見的去識別化處理是模糊化處理，針對結構化資料集，在符合資料被識別出的風險下，以更高階的內容取代實際內容，即所謂的概化(generalization)處理，例如郵遞區號31057以310**取代，'新竹縣竹東鎮中興路四段195號51館'以'新竹縣竹東鎮中興路四段'取代，數字以區間化處理，或是以’單身’取代’未婚’、’喪偶’及’離婚’等，而不符合風險的部分則不提供或是遮罩處理，所謂的K-匿名系列的演算法即是此一代表。
				</p>
				<img src="~/images/deid-pic01.png" alt="">
				<p class="text_info">圖一、個體與資料屬性對應關係</p>
				<img src="~/images/deid-pic02.png" alt="">
				<p class="text_info">圖二、個體與資料屬性去識別化對應關係 (以K-匿名技術說明)</p>
				<br><br><br>
				<h4>風險評估方法說明</h4>
				<p>
					模擬不同身分背景的資料揭露者計算資料揭露風險，包含: 任何人、掌握特定資料人士(兩種類型)、一般資料分析者(兩種類型)。將原始資料(raw dataset)及去識別化資料(de-id dataset) 根據使用者選取的感興趣欄位來計算風險估值，供使用者參考。<br><br>我們將原始資料(raw dataset)及去識別化資料(de-id dataset)模擬不同揭露者揭露狀況，進行風險評估計算，呈現揭露結果比率(單位%)。
				</p>
				<img class="img_rl" src="~/images/risk_table.png" alt="">
				<h4>可用性評估方法說明</h4>
				<p>
					利用五種機器學習方法 ，包含 : XGBoost、SVM、Random Forest、Linear SVC、Logistic Regression，將原始資料(raw)及去識別化資料(deid)根據使用者選取的感興趣欄位來訓練模型，呈現分類結果正確率，供使用者參考。<br><br>我們將原始資料(raw)及去識別化資料(deid)，分別以80%作為訓練資料、20%作為測試資料，分別建模，提供使用者比較資料去識別化前後的分類結果。
				</p>
				<img class="img_rl" src="~/images/utility_table.png" alt="">
				<p>
					基於隱私保護原則，資料分析人員無法利用原始資料進行分析，因此我們提供模型一，讓資料分析人員瞭解原始資料在選定的感興趣欄位下的分析結果，並與模型二參考比較。
				</p>
			</div>
        </div>
    </div>
</section>