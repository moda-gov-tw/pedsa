2020-02-06 02:41:22 INFO  SignalUtils:54 - Registered signal handler for TERM
2020-02-06 02:41:22 INFO  SignalUtils:54 - Registered signal handler for HUP
2020-02-06 02:41:22 INFO  SignalUtils:54 - Registered signal handler for INT
2020-02-06 02:41:22 INFO  SecurityManager:54 - Changing view acls to: hadoop
2020-02-06 02:41:22 INFO  SecurityManager:54 - Changing modify acls to: hadoop
2020-02-06 02:41:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-02-06 02:41:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-02-06 02:41:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
2020-02-06 02:41:22 INFO  ApplicationMaster:54 - Preparing Local resources
2020-02-06 02:41:23 INFO  ApplicationMaster:54 - ApplicationAttemptId: appattempt_1580953164575_0011_000001
2020-02-06 02:41:23 INFO  ApplicationMaster:54 - Waiting for Spark driver to be reachable.
2020-02-06 02:41:23 INFO  ApplicationMaster:54 - Driver now available: nodemaster:40971
2020-02-06 02:41:23 INFO  TransportClientFactory:267 - Successfully created connection to nodemaster/172.28.1.15:40971 after 54 ms (0 ms spent in bootstraps)
2020-02-06 02:41:23 INFO  ApplicationMaster:54 - 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>//home/hadoop/hadoop/etc/hadoop<CPS>/home/hadoop/hadoop/share/hadoop/common/*<CPS>/home/hadoop/hadoop/share/hadoop/common/lib/*<CPS>/home/hadoop/hadoop/share/hadoop/hdfs/*<CPS>/home/hadoop/hadoop/share/hadoop/hdfs/lib/*<CPS>/home/hadoop/hadoop/share/hadoop/mapreduce/*<CPS>/home/hadoop/hadoop/share/hadoop/mapreduce/lib/*<CPS>/home/hadoop/hadoop/share/hadoop/yarn/*<CPS>/home/hadoop/hadoop/share/hadoop/yarn/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>/home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/*:/home/hadoop/hadoop/share/hadoop/common/*:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop/share/hadoop/hdfs/*:/home/hadoop/hadoop/share/hadoop/yarn/lib/*:/home/hadoop/hadoop/share/hadoop/yarn/*:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop/share/hadoop/mapreduce/*:/home/hadoop/hadoop/contrib/capacity-scheduler/*.jar<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_DIST_CLASSPATH -> /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/*:/home/hadoop/hadoop/share/hadoop/common/*:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop/share/hadoop/hdfs/*:/home/hadoop/hadoop/share/hadoop/yarn/lib/*:/home/hadoop/hadoop/share/hadoop/yarn/*:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop/share/hadoop/mapreduce/*:/home/hadoop/hadoop/contrib/capacity-scheduler/*.jar
    SPARK_YARN_STAGING_DIR -> hdfs://nodemaster:9000/user/hadoop/.sparkStaging/application_1580953164575_0011
    SPARK_USER -> hadoop
    PYTHONPATH -> /home/hadoop/spark/python/lib/pyspark.zip:/home/hadoop/spark/python/lib/py4j-0.10.7-src.zip

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx8192m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=40971' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@nodemaster:40971 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      1 \ 
      --app-id \ 
      application_1580953164575_0011 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __spark_libs__ -> resource { scheme: "hdfs" host: "nodemaster" port: 9000 file: "/user/hadoop/.sparkStaging/application_1580953164575_0011/__spark_libs__3266202327933940511.zip" } size: 234690977 timestamp: 1580956879588 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "nodemaster" port: 9000 file: "/user/hadoop/.sparkStaging/application_1580953164575_0011/__spark_conf__.zip" } size: 99082 timestamp: 1580956880143 type: ARCHIVE visibility: PRIVATE

===============================================================================
2020-02-06 02:41:23 INFO  RMProxy:98 - Connecting to ResourceManager at nodemaster/172.28.1.15:8030
2020-02-06 02:41:23 INFO  YarnRMClient:54 - Registering the ApplicationMaster
2020-02-06 02:41:23 INFO  YarnAllocator:54 - Will request 2 executor container(s), each with 1 core(s) and 8892 MB memory (including 700 MB of overhead)
2020-02-06 02:41:23 INFO  YarnAllocator:54 - Submitted 2 unlocalized container requests.
2020-02-06 02:41:23 INFO  ApplicationMaster:54 - Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
2020-02-06 02:41:24 INFO  AMRMClientImpl:360 - Received new token for : nodemaster:8050
2020-02-06 02:41:24 INFO  YarnAllocator:54 - Launching container container_1580953164575_0011_01_000002 on host nodemaster for executor with ID 1
2020-02-06 02:41:24 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2020-02-06 02:41:24 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2020-02-06 02:41:24 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : nodemaster:8050
2020-02-06 02:41:26 INFO  YarnAllocator:54 - Launching container container_1580953164575_0011_01_000003 on host nodemaster for executor with ID 2
2020-02-06 02:41:26 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2020-02-06 02:41:26 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2020-02-06 02:41:26 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : nodemaster:8050
2020-02-06 02:41:34 INFO  YarnAllocator:54 - Driver requested a total number of 0 executor(s).
2020-02-06 02:41:34 INFO  ApplicationMaster$AMEndpoint:54 - Driver terminated or disconnected! Shutting down. nodemaster:40971
2020-02-06 02:41:34 INFO  ApplicationMaster$AMEndpoint:54 - Driver terminated or disconnected! Shutting down. nodemaster:40971
2020-02-06 02:41:34 INFO  ApplicationMaster:54 - Final app status: SUCCEEDED, exitCode: 0
2020-02-06 02:41:34 INFO  ApplicationMaster:54 - Unregistering ApplicationMaster with SUCCEEDED
2020-02-06 02:41:34 INFO  AMRMClientImpl:382 - Waiting for application to be successfully unregistered.
2020-02-06 02:41:34 INFO  ApplicationMaster:54 - Deleting staging directory hdfs://nodemaster:9000/user/hadoop/.sparkStaging/application_1580953164575_0011
2020-02-06 02:41:34 INFO  ShutdownHookManager:54 - Shutdown hook called
