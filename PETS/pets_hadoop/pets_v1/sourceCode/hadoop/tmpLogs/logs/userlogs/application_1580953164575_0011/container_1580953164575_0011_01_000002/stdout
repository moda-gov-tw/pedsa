2020-02-06 02:41:24 INFO  CoarseGrainedExecutorBackend:2611 - Started daemon with process name: 9431@nodemaster
2020-02-06 02:41:24 INFO  SignalUtils:54 - Registered signal handler for TERM
2020-02-06 02:41:24 INFO  SignalUtils:54 - Registered signal handler for HUP
2020-02-06 02:41:24 INFO  SignalUtils:54 - Registered signal handler for INT
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing view acls to: hadoop
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing modify acls to: hadoop
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-02-06 02:41:25 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
2020-02-06 02:41:25 INFO  TransportClientFactory:267 - Successfully created connection to nodemaster/172.28.1.15:40971 after 53 ms (0 ms spent in bootstraps)
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing view acls to: hadoop
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing modify acls to: hadoop
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-02-06 02:41:25 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-02-06 02:41:25 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
2020-02-06 02:41:25 INFO  TransportClientFactory:267 - Successfully created connection to nodemaster/172.28.1.15:40971 after 0 ms (0 ms spent in bootstraps)
2020-02-06 02:41:25 INFO  DiskBlockManager:54 - Created local directory at /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/blockmgr-a1fbdbdc-b38e-4515-929e-2b2e935db85e
2020-02-06 02:41:25 INFO  MemoryStore:54 - MemoryStore started with capacity 4.1 GB
2020-02-06 02:41:25 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@nodemaster:40971
2020-02-06 02:41:25 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2020-02-06 02:41:25 INFO  Executor:54 - Starting executor ID 1 on host nodemaster
2020-02-06 02:41:25 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35429.
2020-02-06 02:41:25 INFO  NettyBlockTransferService:54 - Server created on nodemaster:35429
2020-02-06 02:41:25 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-02-06 02:41:25 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(1, nodemaster, 35429, None)
2020-02-06 02:41:25 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(1, nodemaster, 35429, None)
2020-02-06 02:41:25 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(1, nodemaster, 35429, None)
2020-02-06 02:41:31 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 1
2020-02-06 02:41:31 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2020-02-06 02:41:31 INFO  Executor:54 - Fetching spark://nodemaster:40971/files/getGenTbl.py with timestamp 1580956876380
2020-02-06 02:41:31 INFO  TransportClientFactory:267 - Successfully created connection to nodemaster/172.28.1.15:40971 after 0 ms (0 ms spent in bootstraps)
2020-02-06 02:41:31 INFO  Utils:54 - Fetching spark://nodemaster:40971/files/getGenTbl.py to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/fetchFileTemp3096129487087640646.tmp
2020-02-06 02:41:31 INFO  Utils:54 - Copying /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/8229762201580956876380_cache to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./getGenTbl.py
2020-02-06 02:41:31 INFO  Executor:54 - Fetching spark://nodemaster:40971/jars/myLogging_jre17_v3.jar with timestamp 1580956876354
2020-02-06 02:41:31 INFO  Utils:54 - Fetching spark://nodemaster:40971/jars/myLogging_jre17_v3.jar to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/fetchFileTemp6090253853772519396.tmp
2020-02-06 02:41:31 INFO  Utils:54 - Copying /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/262038001580956876354_cache to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./myLogging_jre17_v3.jar
2020-02-06 02:41:31 INFO  Executor:54 - Adding file:/home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./myLogging_jre17_v3.jar to class loader
2020-02-06 02:41:31 INFO  Executor:54 - Fetching spark://nodemaster:40971/jars/udfEncrypt_7.jar with timestamp 1580956876355
2020-02-06 02:41:31 INFO  Utils:54 - Fetching spark://nodemaster:40971/jars/udfEncrypt_7.jar to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/fetchFileTemp5975253521657940158.tmp
2020-02-06 02:41:31 INFO  Utils:54 - Copying /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/4281552891580956876355_cache to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./udfEncrypt_7.jar
2020-02-06 02:41:31 INFO  Executor:54 - Adding file:/home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./udfEncrypt_7.jar to class loader
2020-02-06 02:41:31 INFO  Executor:54 - Fetching spark://nodemaster:40971/jars/gen_v9.jar with timestamp 1580956876354
2020-02-06 02:41:31 INFO  Utils:54 - Fetching spark://nodemaster:40971/jars/gen_v9.jar to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/fetchFileTemp8105328506034891853.tmp
2020-02-06 02:41:31 INFO  Utils:54 - Copying /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/21320640051580956876354_cache to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./gen_v9.jar
2020-02-06 02:41:31 INFO  Executor:54 - Adding file:/home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./gen_v9.jar to class loader
2020-02-06 02:41:31 INFO  Executor:54 - Fetching spark://nodemaster:40971/jars/mysql-connector-java-8.0.13.jar with timestamp 1580956876355
2020-02-06 02:41:31 INFO  Utils:54 - Fetching spark://nodemaster:40971/jars/mysql-connector-java-8.0.13.jar to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/fetchFileTemp4694921469427109577.tmp
2020-02-06 02:41:31 INFO  Utils:54 - Copying /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/15045936931580956876355_cache to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./mysql-connector-java-8.0.13.jar
2020-02-06 02:41:31 INFO  Executor:54 - Adding file:/home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./mysql-connector-java-8.0.13.jar to class loader
2020-02-06 02:41:31 INFO  Executor:54 - Fetching spark://nodemaster:40971/jars/address_project_debug_v14.jar with timestamp 1580956876355
2020-02-06 02:41:31 INFO  Utils:54 - Fetching spark://nodemaster:40971/jars/address_project_debug_v14.jar to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/fetchFileTemp6393656491822169746.tmp
2020-02-06 02:41:31 INFO  Utils:54 - Copying /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/12151563231580956876355_cache to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./address_project_debug_v14.jar
2020-02-06 02:41:31 INFO  Executor:54 - Adding file:/home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./address_project_debug_v14.jar to class loader
2020-02-06 02:41:31 INFO  Executor:54 - Fetching spark://nodemaster:40971/jars/myLogging_1.jar with timestamp 1580956876355
2020-02-06 02:41:31 INFO  Utils:54 - Fetching spark://nodemaster:40971/jars/myLogging_1.jar to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/fetchFileTemp189387515852360414.tmp
2020-02-06 02:41:31 INFO  Utils:54 - Copying /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf/-10431978441580956876355_cache to /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./myLogging_1.jar
2020-02-06 02:41:31 INFO  Executor:54 - Adding file:/home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/container_1580953164575_0011_01_000002/./myLogging_1.jar to class loader
2020-02-06 02:41:31 INFO  TorrentBroadcast:54 - Started reading broadcast variable 1
2020-02-06 02:41:31 INFO  TransportClientFactory:267 - Successfully created connection to nodemaster/172.28.1.15:42581 after 1 ms (0 ms spent in bootstraps)
2020-02-06 02:41:31 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 59.3 KB, free 4.1 GB)
2020-02-06 02:41:31 INFO  TorrentBroadcast:54 - Reading broadcast variable 1 took 87 ms
2020-02-06 02:41:31 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 161.4 KB, free 4.1 GB)
2020-02-06 02:41:31 INFO  CodeGenerator:54 - Code generated in 156.728916 ms
2020-02-06 02:41:32 INFO  CodeGenerator:54 - Code generated in 14.33469 ms
2020-02-06 02:41:32 INFO  FileScanRDD:54 - Reading File path: file:///home/hadoop/spark-warehouse/2qdatamarketdeid.db/mac_adult_id/part-00001-62ac88d9-7610-4bdc-8bc6-0286ac2af5e1-c000.snappy.orc, range: 0-110891, partition values: [empty row]
2020-02-06 02:41:32 INFO  CodeGenerator:54 - Code generated in 54.553389 ms
2020-02-06 02:41:32 INFO  CodeGenerator:54 - Code generated in 87.216849 ms
2020-02-06 02:41:32 INFO  TorrentBroadcast:54 - Started reading broadcast variable 0
2020-02-06 02:41:32 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 4.1 GB)
2020-02-06 02:41:32 INFO  TorrentBroadcast:54 - Reading broadcast variable 0 took 9 ms
2020-02-06 02:41:32 INFO  CodeGenerator:54 - Code generated in 67.139369 ms
2020-02-06 02:41:32 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2020-02-06 02:41:32 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 336.9 KB, free 4.1 GB)
2020-02-06 02:41:32 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2020-02-06 02:41:33 INFO  ReaderImpl:531 - Reading ORC rows from file:/home/hadoop/spark-warehouse/2qdatamarketdeid.db/mac_adult_id/part-00001-62ac88d9-7610-4bdc-8bc6-0286ac2af5e1-c000.snappy.orc with {include: [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], offset: 0, length: 110891}
2020-02-06 02:41:33 INFO  RecordReaderFactory:90 - Schema is not specified on read. Using file schema.
2020-02-06 02:41:33 INFO  PythonUDFRunner:54 - Times: total = 1091, boot = 343, init = 720, finish = 28
2020-02-06 02:41:34 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20200206024132_0000_m_000001_0' to file:/home/hadoop/spark-warehouse/2qdatamarketdeid.db/g_mac_adult_id/_temporary/0/task_20200206024132_0000_m_000001
2020-02-06 02:41:34 INFO  SparkHadoopMapRedUtil:54 - attempt_20200206024132_0000_m_000001_0: Committed
2020-02-06 02:41:34 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 3033 bytes result sent to driver
2020-02-06 02:41:34 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2020-02-06 02:41:34 INFO  MemoryStore:54 - MemoryStore cleared
2020-02-06 02:41:34 INFO  BlockManager:54 - BlockManager stopped
2020-02-06 02:41:34 INFO  ShutdownHookManager:54 - Shutdown hook called
2020-02-06 02:41:34 INFO  ShutdownHookManager:54 - Deleting directory /home/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1580953164575_0011/spark-6b07ecb0-b3ea-4472-9cba-f61df6d8dbaf
